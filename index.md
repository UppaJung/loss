---
layout: layouts/index.vto
bodyClass: body-index
templateEngine: [md, vto]
date: Git Last Modified
---

<!-- <div style="display: block; padding: 0.5rem; background-color: rgba(220, 240, 220, 0.5); border-bottom-right-radius: 0.5rem; border-bottom-left-radius: 0.5rem; margin-left: auto; margin-right: auto; text-align: center;">
Your feedback can change what we ask on our next survey! Please post suggestions to our Mastodon feed or email them to <a href="mailto:team@uharm.org">team@uharm.org</a>.
</div> -->

<div style="display: block; position: fixed; z-index: 255; bottom: 0; padding: 0.5rem; background-color: rgba(220, 240, 220, 1); border-top-right-radius: 0.5rem; border-top-left-radius: 0.5rem; margin-left: auto; margin-right: auto; text-align: center;">
Your feedback can change what we ask on our next survey! Please post suggestions to our Mastodon feed or email them to <a href="mailto:team@uharm.org">team@uharm.org</a>.
</div>

## Why don't we know how often security technologies backfire?
We started this research because we know far less about the scale of harm we collectively suffer from security technologies backfiring against us than we do about security technologies failing to protect us from others (breaches). For example, we know more about the prevalence with which people's email or social accounts are broken into than the prevalence with which people are permanently locked out of these accounts.

Backfires are rarely reported or measured because, unlike breaches, there is no legislation requiring their reporting. Further, most backfires impact one user at a time, at a scale too small to be newsworthy, and users often blame themselves. Yet, security technologies can cause as much harm when they backfire as when they are breached; they can prevent us from accessing and services at times of critical need, or they can lock us out permanently. The companies that build and deploy security technologies rarely suffer consequences when their products backfire. These companies are reluctant to measure backfires, and are even more reluctant to report their measurements, as doing so would call attention to their product's potential for harm, leading fewer people to use them. The potential for security technology to backfire will not be addressed unless outsiders draw attention it, or compel companies to report incidents of backfiring.

As our research team set out to gauge the prevalence with which security technologies backfire, and the scale of the collective harm that results, we encountered a challenge: we lacked a baseline for the prevalence and harm we collectively suffer from all the ways in which we have come to rely on technology and how it can fail us. And so, we expanded our survey to answer two complementary questions:

<style>
	ol ol { list-style-type: lower-alpha; } and ol ol ol { list-style-type: lower-roman; }
</style>
<ol>
<li>What is the collective harm of technology failing us, being used against us, or otherwise causing harm?</li>
<li>What is the prevalence and collective harm caused by security technologies backfiring...
		<ol>
		<li>as compared to the harms that result from those technologies failing to protect us from breaches, and</li>
		<li>as compared to the broader harms that result from technology failing us, being used against us, or otherwise causing harm?</li>
		</ol>
</li>
</ol>

## Our survey

We surveyed people to ask about 13 harm events they may or may not have suffered, as well as three harms that need not be attributed to a single specific event.

<figure>
	<img src="/graphs/Pilot11/scenario-harm-likert-percent.svg" alt="TBD"/>
	<figcaption>The percent of <i>pilot</i> participants who reported experiencing events causing harms (the 13 bars on the left) or technology-related harms that they did not need to associate with specific events (the 3 bars on the right). Losses due to failures of security measures to protect participants from attack are paired (left bar) against harms due to security measures themselves harming participants (right bar). Each bar is broken down into colors by the Likert severity of harm each participant reported on a Likert scale.</figcaption><b>Figure 1</b>	
</figure>

We asked about both breach events and backfire events for the security protecting their
  - (1/2) devices,
  - (3/4) email accounts,
  - (5/6) social media accounts,
  - (7/8) financial accounts, and 
  - (9/10) stored passwords (password manager accounts)â€”a total of ten events (five breach events each paired with a backfire event).
	
Another three were events that were not specifically security related and did not have breach/backfire pairings:
  - (11) losing data when replacing a device (e.g., upgrading a phone),
  - (12) having technology fail or behave in a way other than what was promised/expected, and
  - (13) having technology used to abuse, harass, or embarrass them.
  
The three harms we asked about independently of the events that led to the harms were:
  - (14) permanently losing photos,
  - (15) permanently losing emails, and
  - (16) experiencing mental distress or health issues connected with their use of technology.

Some of those events and harms, such as the one about mental health[^mental], were inspired by reading the answers to free-response questions in earlier pilot surveys. Figure 1 shows the fraction of our *pilot* participants who reported these harmful events (1-13) and harms (14-16), broken down by the severity of the harm experienced. Not surprisingly, more participants reported experiencing harms that need not be attributed to a specific event than reported specific events that may have been the cause of harms.

[^mental]: The prevalence of mental-health harms reported was so high we re-checked our data. Note that following the first ten participants of this pilot, we discovered that participants were only randomly assigned two of the three harms. We fixed this for the remaining participants, and corrected the percentages of those who reported each harm remove those who weren't given the opportunity to report that harm. We had already made this adjustment when noticing just how prevalent mental-health concerns were among our (relatively small) pilot group.

One might wonder whether participants would have attributed the same significance to these events and harms significant had we not prompted them with questions about them and asked them to rate them on a 7-point scale. This is why, prior to introducing these events and harms, we began our survey by asking participants simply to describe, without prompting, "the three most harmful technology-related harms or losses" they had experienced. When we later asked about each of the 13 events and 3 harms specific to our survey, we asked participants if they included the event or harm as part of three worst harms they had described unprompted, or whether, in retrospect, they should have included it. See Figure 2 which reveals, for example, that every one of the pilot participants who reported mental-health harms connected this concern back to one of the their initial three experiences they described in free responses.

<figure>
  <img src="/graphs/Pilot11/scenario-bar-chart.svg" alt="A bar chart summarizing the percent of participants who had experienced each harm scenario."/>
  <figcaption>The percent of <i>pilot</i> participants who reported experiencing events causing harms (the 13 bars on the left) or technology-related harms that they did not need to associate with specific events (the 3 bars on the right). Losses due to failures of security measures to protect participants from attack are paired (left bar) against harms due to security measures themselves harming participants (right bar). Each bar is broken down into colors based on whether the participant connected the experience/harm to one of the three worst experiences they described at the start of the study ("original"), whether they said they should have included the experience/harm as one of their three worst ("revised"), or whether it did not warrant a position in their top three ("not worst"). Those that had suffered the experience/harm are broken down into those who believe the harm could or could not happen to them.</figcaption><b>Figure 2</b>
</figure>




